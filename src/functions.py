import numpy as np
import matplotlib.pyplot as plt
import itertools
from sklearn.metrics import confusion_matrix
import os
from sklearn.metrics import roc_auc_score

def save_metrics(model, X, y, target_names, batch_size, path):
    y_pred = model.predict(X, batch_size=batch_size)
    y_pred = np.argmax(y_pred, axis=1)

    # https://stackoverflow.com/a/51295451
    roc_score = roc_auc_score(y, 1 - y_pred.reshape(-1, 1))

    cm = confusion_matrix(y.argmax(axis=1), y_pred)

    # Make plot
    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title('Confusion Matrix {:.4f}'.format(roc_score))
    plt.colorbar()

    tick_marks = np.arange(len(target_names))
    plt.xticks(tick_marks, target_names, rotation=45)
    plt.yticks(tick_marks, target_names)

    thresh = cm.max() / 1.5
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                    horizontalalignment="center",
                    color="white" if cm[i, j] > thresh else "black")
        
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))

    plt.savefig(os.path.join(path, 'confusion_matrix.png'))